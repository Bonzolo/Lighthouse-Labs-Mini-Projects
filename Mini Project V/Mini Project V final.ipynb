{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973d930a-b31a-48d7-8a2e-c01ef4a4761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import string\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import collections\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978fd48-025a-47c2-ad55-acb7e9274eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be046c-afff-458c-b651-3d9d7e8007e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15857234-2e68-4a01-abb6-3d45e15fc70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69b285bf-1852-4d71-bbad-99de2b8c449e",
   "metadata": {},
   "source": [
    "# Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753073f6-adcd-406e-b74d-237701836e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TsinghuaBilingualCorpus/HK.txt',encoding=\"utf8\") as f:\n",
    "    output = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654d5c43-1aa3-4c54-911f-e7abf37adb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = output.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b2ccc14-9201-47df-9252-0888eb35a511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1261558"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838f7f1-7dad-4569-8dbd-42ebc0ac410e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e39c140-d3ba-46e4-b2f8-f55c8f9d4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "c_filter = []\n",
    "for i in range(0,len(text),2):\n",
    "    if len(text[i]) <=10 and (all(x not in alphabet for x in text[i])):\n",
    "        c_filter.append(text[i])\n",
    "        c_filter.append(text[i+1])\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "e_filter = []\n",
    "for i in range(1,len(c_filter),2):\n",
    "    if (len(c_filter[i]) <=20) and (all(x in alphabet or x.isspace() for x in c_filter[i])):\n",
    "        e_filter.append(c_filter[i-1])\n",
    "        e_filter.append(c_filter[i])\n",
    "    else: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c687238-66f7-4bbc-87d3-015305040e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33070"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f40e0570-57ef-45d5-a84e-67fa1e8fd4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_en_dict = {e_filter[i]: e_filter[i + 1] for i in range(0, len(e_filter), 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9fe78d-380b-4b9c-aa84-f796ba0853c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of eng and ch sentences\n",
    "eng = list(ch_en_dict.values())\n",
    "ch = list(ch_en_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7341ad70-836f-473b-86ab-a1b6a766b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for i in range(len(eng)):\n",
    "    tmp = [eng[i],ch[i]]\n",
    "    train.append(tmp)\n",
    "\n",
    " # train, test = train_test_split(train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccac1e54-7b9e-4069-acf5-74a9bd9ad85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13149"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff33c7ea-ec69-4d40-8c26-dec22403962f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13149"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "721e9238-769d-4af6-be87-9add521e0ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Steambun\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.519 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in eng for word in sentence.split()])\n",
    "chinese_words_counter = collections.Counter([word for sentence in ch for word in list(jieba.cut(sentence,cut_all = False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99be638f-0872-47eb-a79f-26945ab22321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7185 unique English words.\n",
      "13149 English words.\n",
      "\n",
      "9509 unique Chinese characters.\n",
      "13149 Chinese characters.\n"
     ]
    }
   ],
   "source": [
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('{} English words.'.format(len(eng)))\n",
    "#print('10 Most common words in the English dataset:')\n",
    "#print('\"' + '\" \"'.join(list(zip(*eng.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} unique Chinese characters.'.format(len(chinese_words_counter)))\n",
    "print('{} Chinese characters.'.format(len(ch)))\n",
    "#print('10 Most common words in the Chinese dataset:')\n",
    "#print('\"' + '\" \"'.join(list(zip(*ch.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67aca85-b9e5-4c4d-934c-def2e9132703",
   "metadata": {},
   "source": [
    "# Clean Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f312b14-9b5b-45a7-a3d3-60be4c1d3e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6310fef8-79c2-4381-a709-422995760849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove punctuation in our messages and lower case\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text.lower()\n",
    "\n",
    "for i in range(len(eng)):\n",
    "    eng[i] = remove_punct(eng[i])\n",
    "    \n",
    "for i in range(len(ch)):\n",
    "    ch[i] = remove_punct(ch[i])\n",
    "    ch[i] = list(jieba.cut(ch[i],cut_all = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d14a373-562b-4242-8203-aea96462d1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skip to search box '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54d3ed87-2e7e-4b9e-bf8e-d2953d0201a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n"
     ]
    }
   ],
   "source": [
    "seg_list = list(jieba.cut(\"我来到北京清华大学\", cut_all=False))\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac831d9-1e91-4fa7-8c1e-a944bb3aca9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "983fbfcc-0e4c-405f-b18c-666a475c86f8",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3866637e-d860-44ad-9bdd-ce4ddc05aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a9730e1-d911-4233-a9bf-4d52493a82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokenizer = tokenize(eng)\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "ch_tokenizer = tokenize(ch)\n",
    "ch_vocab_size = len(ch_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66d89f15-6f0e-4360-b606-8ea0a2d5e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['跳至', '搜寻']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "898e444c-2717-437c-8ee8-5775898361bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1619, 162],\n",
       " [1619, 2263],\n",
       " [2264],\n",
       " [79, 53],\n",
       " [76, 2],\n",
       " [19],\n",
       " [119, 1, 3648, 3649],\n",
       " [2263],\n",
       " [608, 541],\n",
       " [162]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_tokenizer.texts_to_sequences(ch[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9172699-394d-4322-9a25-2699cd38d7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1309, 6, 82, 629],\n",
       " [1309, 6, 303, 942],\n",
       " [630],\n",
       " [117, 943],\n",
       " [13],\n",
       " [631, 54],\n",
       " [118, 1310],\n",
       " [303, 942],\n",
       " [712],\n",
       " [105, 82]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer.texts_to_sequences(eng[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "147e642a-a31a-43f2-821b-6d4d11669403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "         # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "         # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "279c4e78-929a-4b53-8541-23955b4e72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2599c3-c6d6-4e61-86ef-56ea9e1976a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9dc2311-cf1e-46d8-a2e0-1898352125a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eng = max_length(eng)\n",
    "max_ch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75965b49-d6ee-41f6-8ecc-af2952de54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = np.array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281420c6-8f1b-4634-bf59-6a61722d706c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b7d72-4362-4303-ad82-696e8260a2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320bfacd-7b32-4609-8662-5eb8f3370cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4edb6028-3fa2-48ce-b503-ee51da04d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(encode_sequences(eng_tokenizer,max_eng,eng),encode_sequences(ch_tokenizer,max_ch,ch), test_size=0.20, random_state=42)\n",
    "trainY = encode_output(trainY, ch_vocab_size)\n",
    "testY = encode_output(testY, ch_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de8eec-c839-4bf3-988a-72dc38a3ab3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caee815f-7f2a-4ce2-a195-e474728d22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04ba4fc2-5a5e-42c8-ba3e-785727af8182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 5, 200)            1119800   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 10, 9501)          1909701   \n",
      "=================================================================\n",
      "Total params: 3,671,101\n",
      "Trainable params: 3,671,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# define NMT model\n",
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.005\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model\n",
    "\n",
    "# define model\n",
    "model = define_model(eng_vocab_size, ch_vocab_size, max_eng, max_ch, 200)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "# summarize defined model\n",
    "print(model.summary())\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897dab7e-c5d8-4e66-b87f-56524d769d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "faa95b54-f8a1-4445-806f-eb39939b2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#with tf.device('/CPU:0'):\n",
    "#    model.fit(X_train, y_train,epochs=1, batch_size=512, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e15dbad1-0caf-49f2-b815-bb452d52df8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1449 - val_loss: 2.7267\n",
      "Epoch 2/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1456 - val_loss: 2.7395\n",
      "Epoch 3/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1463 - val_loss: 2.7437\n",
      "Epoch 4/100\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1445 - val_loss: 2.7502\n",
      "Epoch 5/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1432 - val_loss: 2.7482\n",
      "Epoch 6/100\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1425 - val_loss: 2.7420\n",
      "Epoch 7/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1421 - val_loss: 2.7434\n",
      "Epoch 8/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1418 - val_loss: 2.7524\n",
      "Epoch 9/100\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1416 - val_loss: 2.7443\n",
      "Epoch 10/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1422 - val_loss: 2.7476\n",
      "Epoch 11/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1420 - val_loss: 2.7460\n",
      "Epoch 12/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1419 - val_loss: 2.7501\n",
      "Epoch 13/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1424 - val_loss: 2.7584\n",
      "Epoch 14/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1423 - val_loss: 2.7508\n",
      "Epoch 15/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1413 - val_loss: 2.7552\n",
      "Epoch 16/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1416 - val_loss: 2.7489\n",
      "Epoch 17/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1417 - val_loss: 2.7496\n",
      "Epoch 18/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1416 - val_loss: 2.7536\n",
      "Epoch 19/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1418 - val_loss: 2.7662\n",
      "Epoch 20/100\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1419 - val_loss: 2.7641\n",
      "Epoch 21/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1426 - val_loss: 2.7608\n",
      "Epoch 22/100\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1431 - val_loss: 2.7632\n",
      "Epoch 23/100\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1425 - val_loss: 2.7649\n",
      "Epoch 24/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1411 - val_loss: 2.7715\n",
      "Epoch 25/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1397 - val_loss: 2.7602\n",
      "Epoch 26/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1391 - val_loss: 2.7659\n",
      "Epoch 27/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1384 - val_loss: 2.7688\n",
      "Epoch 28/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1385 - val_loss: 2.7655\n",
      "Epoch 29/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1384 - val_loss: 2.7604\n",
      "Epoch 30/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1399 - val_loss: 2.7727\n",
      "Epoch 31/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1403 - val_loss: 2.7756\n",
      "Epoch 32/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1401 - val_loss: 2.7643\n",
      "Epoch 33/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1407 - val_loss: 2.7783\n",
      "Epoch 34/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1404 - val_loss: 2.7793\n",
      "Epoch 35/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1398 - val_loss: 2.7736\n",
      "Epoch 36/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1408 - val_loss: 2.7802\n",
      "Epoch 37/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1418 - val_loss: 2.7736\n",
      "Epoch 38/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1420 - val_loss: 2.7806\n",
      "Epoch 39/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1402 - val_loss: 2.7802\n",
      "Epoch 40/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1387 - val_loss: 2.7767\n",
      "Epoch 41/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1377 - val_loss: 2.7877\n",
      "Epoch 42/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1378 - val_loss: 2.7805\n",
      "Epoch 43/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1377 - val_loss: 2.7860\n",
      "Epoch 44/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1373 - val_loss: 2.7847\n",
      "Epoch 45/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1377 - val_loss: 2.7848\n",
      "Epoch 46/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1380 - val_loss: 2.7897\n",
      "Epoch 47/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1382 - val_loss: 2.7884\n",
      "Epoch 48/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1387 - val_loss: 2.7901\n",
      "Epoch 49/100\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1384 - val_loss: 2.7922\n",
      "Epoch 50/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1386 - val_loss: 2.7875\n",
      "Epoch 51/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1381 - val_loss: 2.7878\n",
      "Epoch 52/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1378 - val_loss: 2.7794\n",
      "Epoch 53/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1377 - val_loss: 2.7898\n",
      "Epoch 54/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1379 - val_loss: 2.7981\n",
      "Epoch 55/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1382 - val_loss: 2.7945\n",
      "Epoch 56/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1383 - val_loss: 2.7947\n",
      "Epoch 57/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1381 - val_loss: 2.7910\n",
      "Epoch 58/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1376 - val_loss: 2.7936\n",
      "Epoch 59/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1371 - val_loss: 2.7990\n",
      "Epoch 60/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1391 - val_loss: 2.7925\n",
      "Epoch 61/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1403 - val_loss: 2.7933\n",
      "Epoch 62/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1395 - val_loss: 2.7989\n",
      "Epoch 63/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1370 - val_loss: 2.8010\n",
      "Epoch 64/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1362 - val_loss: 2.7981\n",
      "Epoch 65/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1357 - val_loss: 2.8076\n",
      "Epoch 66/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1353 - val_loss: 2.7963\n",
      "Epoch 67/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1356 - val_loss: 2.8055\n",
      "Epoch 68/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1352 - val_loss: 2.7977\n",
      "Epoch 69/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1358 - val_loss: 2.7987\n",
      "Epoch 70/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1360 - val_loss: 2.7987\n",
      "Epoch 71/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1373 - val_loss: 2.8070\n",
      "Epoch 72/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1373 - val_loss: 2.8054\n",
      "Epoch 73/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1368 - val_loss: 2.8048\n",
      "Epoch 74/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1371 - val_loss: 2.7975\n",
      "Epoch 75/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1378 - val_loss: 2.8127\n",
      "Epoch 76/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1376 - val_loss: 2.8010\n",
      "Epoch 77/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1379 - val_loss: 2.8110\n",
      "Epoch 78/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1371 - val_loss: 2.8077\n",
      "Epoch 79/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1364 - val_loss: 2.8048\n",
      "Epoch 80/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1365 - val_loss: 2.8123\n",
      "Epoch 81/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1351 - val_loss: 2.8093\n",
      "Epoch 82/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1345 - val_loss: 2.8198\n",
      "Epoch 83/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1346 - val_loss: 2.8137\n",
      "Epoch 84/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1346 - val_loss: 2.8173\n",
      "Epoch 85/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1345 - val_loss: 2.8171\n",
      "Epoch 86/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1351 - val_loss: 2.8154\n",
      "Epoch 87/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1358 - val_loss: 2.8199\n",
      "Epoch 88/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1359 - val_loss: 2.8119\n",
      "Epoch 89/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1358 - val_loss: 2.8142\n",
      "Epoch 90/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1360 - val_loss: 2.8117\n",
      "Epoch 91/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1376 - val_loss: 2.8071\n",
      "Epoch 92/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1399 - val_loss: 2.8046\n",
      "Epoch 93/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1402 - val_loss: 2.8077\n",
      "Epoch 94/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1375 - val_loss: 2.8055\n",
      "Epoch 95/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1359 - val_loss: 2.8209\n",
      "Epoch 96/100\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.1343 - val_loss: 2.8211\n",
      "Epoch 97/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1338 - val_loss: 2.8189\n",
      "Epoch 98/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1341 - val_loss: 2.8264\n",
      "Epoch 99/100\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.1337 - val_loss: 2.8222\n",
      "Epoch 100/100\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.1337 - val_loss: 2.8229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x289edca4d00>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "#filename = 'model.h5'\n",
    "#checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=32, validation_data=(testX, testY),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd4bf63a-4686-4690-993a-eb9b2b160624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        # translate encoded source text\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_sequence(model, eng_tokenizer, source)\n",
    "        raw_target, raw_src = raw_dataset[i]\n",
    "        if i < 10:\n",
    "            print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "        actual.append([raw_target.split()])\n",
    "        predicted.append(translation.split())\n",
    "    # calculate BLEU score\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f1140ec-1e73-4fd4-9a31-5bccf59d9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c089136-b24d-455b-812e-b80dfabd75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [np.argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "460b5576-7fee-4954-90b1-0dd2041c5352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "# test on some training sequences\n",
    "print('train')\n",
    "#evaluate_model(model, eng_tokenizer, trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "#evaluate_model(model, ch_tokenizer, testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db3d2a-5bf3-403d-a405-7bf860a7b590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de07bc8b-5808-4bae-bc68-097d82122720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'注册 名单'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('all I want for christmas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c663fb2-0880-430c-b498-f1c57097f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#food,horse,concrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc16a362-790c-47f3-a357-9a68bc8ec4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31ec0676-07ae-4651-9357-04b7f4cb8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    text = remove_punct(text)\n",
    "    text = encode_sequences(eng_tokenizer,max_eng,text.split())\n",
    "    return predict_sequence(model,ch_tokenizer,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0618fcd-7a5f-4ca2-879a-8002e6ae5d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92206fd5-6eea-4098-88e5-9bef426c523c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2bd40f-3db7-4d50-8109-2de364beeadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ec726-f02c-4973-bc9a-b4f47e05e067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fbf57e-e8c6-4ac1-ac8b-2d5c67c106fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60072fd7-e911-4c13-8aa4-43d720f19cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b79ac-6ca4-4497-a6a3-40401f80395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b52b0-adc4-4ad9-9459-322787473623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
